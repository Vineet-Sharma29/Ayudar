{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDF (tuples, header):\n",
    "    '''Assumes tuples as Python tuples both empty or non empty; header as a tuple with a convention \n",
    "       as (RollNumber, Name, Exam-[name]-[max-marks], ..., Lab-[name]-[max-marks], ..., \n",
    "       Asgn-[name]-[max-marks], ..., Oth-[name]-[max-marks],)\n",
    "       \n",
    "       Returns a Pandas DataFrame with all NULL values replaced by Cipher, and adds a fraud column\n",
    "       for figuring out cheating factor for later functions.'''\n",
    "    \n",
    "    #make rows, column IDs and marks as a list for DataFrame initialization\n",
    "    row_index = [int(i) for i in range(1, len(tuples) + 1)]\n",
    "    col_index = list(header)\n",
    "    values = list(tuples)\n",
    "    \n",
    "    #DataFrame initialisation\n",
    "    df = pd.DataFrame(tuples, row_index, col_index)\n",
    "    \n",
    "    #Handling of NULLs\n",
    "    for col in list(df.columns):\n",
    "        df[col] = df[col].fillna(value = 0)\n",
    "        \n",
    "    #Make a copy of last given exams marks\n",
    "    df['fraud'] = 0\n",
    "    df['fraud'] = df[df.columns[-2]]\n",
    "\n",
    "    return df\n",
    "\n",
    "def scaleMarks (df):\n",
    "    '''Assumes df as a Pandas DataFrame.\n",
    "    \n",
    "       Returns a Pandas DataFrame with marks scaled up according to the max-marks defined in the \n",
    "       column headings'''\n",
    "    \n",
    "    #iterate through all columns and scale marks using apply() attribute of DataFrames\n",
    "    for exam in list(df.columns):\n",
    "        if len(exam.split('-')) > 2:\n",
    "            df[exam] = df[exam].apply(lambda x : (x*100)/int(exam.split('-')[2]))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def createAvg (marks):\n",
    "    '''Assumes marks as a Pandas DataFrame.\n",
    "    \n",
    "       Returns a DataFrame with added columns for overall weighted average, and individual exam,\n",
    "       lab, assignments and other evaluations average'''\n",
    "    \n",
    "    #initilaize columns as zero\n",
    "    marks['overall'] = 0\n",
    "    marks['avgExam'] = 0\n",
    "    marks['avgLab'] = 0\n",
    "    marks['avgAsgn'] = 0\n",
    "    marks['avgOth'] = 0\n",
    "    \n",
    "    #initialize count variables as zero\n",
    "    exams = 0\n",
    "    lab = 0\n",
    "    asgn = 0\n",
    "    oth = 0\n",
    "\n",
    "    #iterate through the column list, filter and sum based on '-' as the additional columns do not have a '-'\n",
    "    for exam in list(marks.columns):\n",
    "        if exam.lower().startswith('exam'):\n",
    "            marks['avgExam'] += marks[exam]\n",
    "            exams += 1  \n",
    "            \n",
    "        elif exam.lower().startswith('lab'):\n",
    "            marks['avgLab'] += marks[exam]\n",
    "            lab += 1\n",
    "            \n",
    "        elif exam.lower().startswith('asgn'):\n",
    "            marks['avgAsgn'] += marks[exam]\n",
    "            asgn += 1\n",
    "            \n",
    "        elif exam.lower().startswith('oth'):\n",
    "            marks['avgOth'] += marks[exam]\n",
    "            oth += 1\n",
    "            \n",
    "        else :\n",
    "            continue\n",
    "    \n",
    "    #weight and scale marks and divide by total number of instances of similar type counted.\n",
    "    #Weights based on the strictness  and students' interest in overall exam process\n",
    "    marks['overall'] = 0.5*marks['avgExam']/exams + 0.3*marks['avgLab']/lab + 0.1*marks['avgAsgn']/asgn + 0.1*marks['avgOth']/oth\n",
    "    \n",
    "    return marks\n",
    "\n",
    "def createChMarks (marks):\n",
    "    '''Assumes marks as a Pandas DataFrame.\n",
    "       \n",
    "       Returns a DataFrame with added column ChMarks which would be used further for overall cheating status'''\n",
    "    \n",
    "    #Not included marks for Assignments as they are done by students AT HOME\n",
    "    marks['ChMarks'] = (marks['avgExam'] + marks['avgLab'] + marks['avgOth'])/3\n",
    "    return marks\n",
    "\n",
    "def variance(df):\n",
    "    '''Assumes df as a Pandas DataFrame.\n",
    "    \n",
    "       Returns the same DataFrame with added column for variance which has variance for all scores for a particular\n",
    "       student'''\n",
    "    \n",
    "    #Figure out first the columns to be considered for variance calculation. Used '-' as an identifier again\n",
    "    ls = list(df.columns)\n",
    "    buffer = []\n",
    "    for i in range(len(ls)):\n",
    "        if len(ls[i].split('-')) > 2:\n",
    "            buffer.append(ls[i])\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    #initialise column var with iteration based indices so as to use the power of apply() attribute\n",
    "    df['var'] = [int(i) for i in range(len(df[df.columns[0]]))]\n",
    "    \n",
    "    #make a dummy row index for slicing DataFrame for calculation\n",
    "    row_index = [int(i) for i in range(1, 1 + len(df[df.columns[0]]))]\n",
    "    \n",
    "    #use the value in var as an indirect reference for the whole row and use the describe() attribute to get std\n",
    "    df['var'] = df['var'].apply(lambda x : (df.loc[row_index,buffer].iloc[x].describe()['std'])**2)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def CI(marks, column):\n",
    "    '''Assumes marks as a Pandas DataFrame and column and a string.\n",
    "    \n",
    "       Returns the 95% confidence interval for the given data as a tuple with entries as (low, high)'''\n",
    "    \n",
    "    column = str(column)\n",
    "    \n",
    "    #CI = mean +- 2*std_error; std_error = std_deviation/sqrt(total observations)\n",
    "    std_error = marks[column].describe()['std']/(len(marks['avgExam']))**0.5\n",
    "    mean = marks[column].describe()['mean']\n",
    "    \n",
    "    return (mean - 2*std_error, mean + 2*std_error,)\n",
    "\n",
    "def width(tup):\n",
    "    '''Assumes tup as tuple.\n",
    "    \n",
    "       Returns an integer as the difference of 2nd and 1st values of tuple'''\n",
    "    \n",
    "    return tup[1] - tup[0]\n",
    "\n",
    "def CourseStats(marks):\n",
    "    '''Assumes marks as a Pandas DataFrame.\n",
    "    \n",
    "       Returns a tuple with values as : (course_difficulty, cheat_risk, list(cheat_flagged), \n",
    "                                         avg_marks, quartile1, quartile2, quartile3,)\n",
    "                                         \n",
    "       course_difficulty (str) : HIGH/MODERATE/EASY based on the weighted average and cut-off marks\n",
    "       cheat_risk (str) : HIGH/MODERATE/LOW based on the spread of Assignment and Other Exam marks\n",
    "       cheat_flagged (list) : A list of 5 RollNumbers who we believe with some confidence are \n",
    "                              indulged in academic malpractices in the class as a whole.\n",
    "       avg_marks (str) : A range of marks where the most of students lie in between.\n",
    "       quartile1, quartile2, quartile3 (int) : The stastical quartile scores for the overall analysis.'''\n",
    "    \n",
    "    #Calculate course difficulty based on 3rd Quartile scores of students.\n",
    "    marker = marks['overall'].describe()['75%']\n",
    "    if marker > 0 and marker <40 :\n",
    "        course_difficulty = \"HIGH\"\n",
    "    elif marker > 40 and marker < 75 :\n",
    "        course_difficulty = \"MODERATE\"\n",
    "    else :\n",
    "        course_difficulty = \"EASY\"\n",
    "        \n",
    "    #Calculate the probability of cheating based on the width of assignment scores and other marks combined    \n",
    "    cheatProb = 1 - width(CI(marks, 'avgAsgn'))/width(CI(marks, 'ChMarks'))\n",
    "    if cheatProb > 0.7 and cheatProb < 1 :\n",
    "        cheat_risk = \"HIGH\"\n",
    "    elif cheatProb >0.4 and cheatProb < 0.7 :\n",
    "        cheat_risk = \"MODERATE\"\n",
    "    else :\n",
    "        cheat_risk = \"LOW\"\n",
    "    \n",
    "    #Flag out top 5 students whose overall scores and assignment socres tell two different stories\n",
    "    marks['cheatflagged'] = 0\n",
    "    marks['cheatflagged'] = marks['avgAsgn'] - df['ChMarks']\n",
    "    cheat_flagged = marks.sort_values('cheatflagged', ascending = False)['RollNumber'].iloc[1:6]\n",
    "    \n",
    "    #Calculate the range of marks for most students\n",
    "    avg_marks = str(CI(df,'overall')[0]) + '-' + str(CI(df,'overall')[1])\n",
    "    \n",
    "    #Calculate quartile scores for weighted marks\n",
    "    quartile1 = marks['overall'].describe()['25%']\n",
    "    quartile2 = marks['overall'].describe()['50%']\n",
    "    quartile3 = marks['overall'].describe()['75%']\n",
    "    \n",
    "    return (course_difficulty, cheat_risk, list(cheat_flagged), avg_marks, quartile1, quartile2, quartile3,)\n",
    "\n",
    "def ExamStats(marks):\n",
    "    '''Assumes marks as a Pandas DataFrame.\n",
    "    \n",
    "       Returns a tuple with values as : (exam_difficulty, cheat_risk, list(cheat_flagged), \n",
    "                                         avg_marks, quartile1, quartile2, quartile3,)\n",
    "                                         \n",
    "       exam_difficulty (str) : HIGH/MODERATE/EASY based on the exam performance\n",
    "       cheat_risk (str) : HIGH/MODERATE/LOW based on the unevenness in marks\n",
    "       cheat_flagged (list) : A list of 5 RollNumbers who we believe with some confidence should\n",
    "                              be re-evaluated\n",
    "       avg_marks (str) : A range of marks where the most of students lie in between.\n",
    "       quartile1, quartile2, quartile3 (int) : The stastical quartile scores for the overall analysis.'''\n",
    "    \n",
    "    #Figure out the name of last exam and store it in location\n",
    "    temp = list(marks.columns)\n",
    "    count = 1\n",
    "    for i in range(len(temp)):\n",
    "        if len(temp[i].split('-')) > 2 :\n",
    "            count += 1\n",
    "    location = temp[count]\n",
    "    \n",
    "    #Calculate the difficulty based on 2nd quartile cut-offs\n",
    "    marker = marks[location].describe()['50%']\n",
    "    if marker > 0 and marker <40 :\n",
    "        exam_difficulty = \"HIGH\"\n",
    "    elif marker > 40 and marker < 75 :\n",
    "        exam_difficulty = \"MODERATE\"\n",
    "    else :\n",
    "        exam_difficulty = \"EASY\"\n",
    "        \n",
    "    #Build the frequency table for digit occurences, add the numbers not present in DataFrame with zero occurence\n",
    "    freq_df = df['fraud'].apply(lambda x : int(x%10)).value_counts()\n",
    "    for i in range (10):\n",
    "        try:\n",
    "            if freq_df.loc[i] >= 0:\n",
    "                continue\n",
    "        except:\n",
    "            freq_df.loc[i] = 0\n",
    "    \n",
    "    #Calculate the variance of the same Dataframe and figure out cheating risk\n",
    "    cheat_var = freq_df.describe()['std']**2\n",
    "    if cheat_var < 15 :\n",
    "        cheat_risk = 'LOW'\n",
    "    if cheat_var > 15 and cheat_var < 80 :\n",
    "        cheat_risk = 'MODERATE'\n",
    "    else:\n",
    "        cheat_risk = 'HIGH'\n",
    "    \n",
    "    #Find the number with most occurences, sample 5 random roll numbers with that number for re-evaluation\n",
    "    max_repeat = freq_df.index[0]\n",
    "    marks['fraud'] = marks['fraud'].apply(lambda x : int(x%10))\n",
    "    suspicious = marks[marks['fraud'] == max_repeat]['fraud']\n",
    "    check_sheets_index = random.sample(range(len(suspicious)), 5)\n",
    "    cheat_flagged = []\n",
    "    for index in check_sheets_index:\n",
    "        cheat_flagged.append(marks['RollNumber'].iloc[index])\n",
    "       \n",
    "    #Calculate the range of marks for most students\n",
    "    avg_marks = str(CI(df,location)[0]) + '-' + str(CI(df,location)[1])\n",
    "    \n",
    "    #Calculate quartile scores for exam marks\n",
    "    quartile1 = marks[location].describe()['25%']\n",
    "    quartile2 = marks[location].describe()['50%']\n",
    "    quartile3 = marks[location].describe()['75%']\n",
    "    \n",
    "    return (exam_difficulty, cheat_risk, cheat_flagged, avg_marks, quartile1, quartile2, quartile3,)\n",
    "        \n",
    "\n",
    "def PersistentLabels(df):\n",
    "    '''Assumes df as a Pandas DataFrame.\n",
    "    \n",
    "       Returns a tuple with values as (consistent, moderately_varying, highly_varying,)\n",
    "       \n",
    "       consistent (list) : RollNumbers have almost no variation in their marks obtained so far.\n",
    "       moderately_varying (list) : RollNumbers have some variation in their marks obtained so far.\n",
    "       highly_varying (list) : RollNumbers have a high variation in their marks obtained so far.'''\n",
    "    \n",
    "    #calculate and filter the roll number list\n",
    "    consistent =  list(df[df['var'] < 30]['RollNumber'])\n",
    "    moderately_varying = list(df[(df['var'] > 30) & (df['var'] < 150)]['RollNumber'])\n",
    "    highly_varying = list(df[df['var'] > 150]['RollNumber'])\n",
    "    \n",
    "    return (consistent, moderately_varying, highly_varying,)\n",
    "\n",
    "\n",
    "def PerformanceLabels(df):\n",
    "    '''Assumes df as a Pandas DataFrame.\n",
    "    \n",
    "       Returns a tuple with values as (exceptional, promising, average, needy,)\n",
    "       \n",
    "       exceptional (list) : RollNumbers with really good performance overall.\n",
    "       promising (list) : RollNumbers who can be pushed to top with a little efforts.\n",
    "       average (list) : RollNumbers who are just a few steps from failing marks and need some attention.\n",
    "       needy (list) : RollNumbers who are in an immediate need of attention.'''\n",
    "    \n",
    "    #Calculate and filter the roll number list\n",
    "    exceptional = list(df[df['overall'] > 85]['RollNumber'])\n",
    "    promising = list(df[(df['overall'] < 85) & (df['overall'] > 50)]['RollNumber'])\n",
    "    average = list(df[(df['overall'] < 50) & (df['overall'] > 30)]['RollNumber'])\n",
    "    needy = list(df[df['overall'] < 30]['RollNumber'])\n",
    "    \n",
    "    return (exceptional, promising, average, needy,)\n",
    "\n",
    "def mainFunc(df):\n",
    "    df['temp'] = 1/df['overall'] + df['var']\n",
    "    \n",
    "    return list(df.sort_values('temp', ascending = False)['RollNumber'][0:5])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    df = makeDF(tuples, headers)\n",
    "    df = scaleMarks(df)\n",
    "    df = createAvg(df)\n",
    "    df = createChMarks(df)\n",
    "    df = variance(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples = np.random.randn(267, 14)\n",
    "headers =  ['RollNumber', 'Name', 'exam-mid-35', 'exam-end-50', 'lab-basic01-20','lab-basic02-20','lab-basic03-20','asgn-basic01-15','asgn-basic02-15','asgn-basic03-15','asgn-basic04-15','oth-quiz01-30', 'oth-quiz02-30', 'oth-quiz03-30']\n",
    "roll = [i for i in range(1, 268)]\n",
    "max_marks = [1, 1, 35, 50, 20, 20, 20, 15, 15, 15, 15, 30, 30, 30]\n",
    "df = pd.DataFrame(tuples)\n",
    "for i in range(14):\n",
    "    df[i] = df[i].apply(lambda x : int((x*100)%max_marks[i]))\n",
    "df.columns = headers\n",
    "df['RollNumber'] = roll\n",
    "df['fraud'] = 0\n",
    "df['fraud'] = df['oth-quiz03-30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = scaleMarks(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = createAvg(df)\n",
    "df = createChMarks(df)\n",
    "df = variance(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CourseStats(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExamStats(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PersistentLabels(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PerformanceLabels(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainFunc(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
